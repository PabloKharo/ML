{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим наш датасет и разделим его на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weatherAfter.csv', index_col=0)\n",
    "x = data.drop(['RainTomorrow'], axis=1).to_numpy()\n",
    "y = np.array(data['RainTomorrow'])\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для оценки качества предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(preds, test):\n",
    "    print(\"Accuracy: {}\".format(accuracy_score(preds, test)))\n",
    "    print(\"Recall: {}\".format(recall_score(preds, test)))\n",
    "    print(\"Precision: {}\".format(precision_score(preds, test)))\n",
    "    print(\"Roc-auc: {}\".format(roc_auc_score(preds, test)))\n",
    "    print(\"Confusion matrix:\\n{}\".format(confusion_matrix(preds, test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n = 200, lr = 0.1, threshold = 0.5):      \n",
    "        self.lr = lr\n",
    "        self.n = int(n)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {\"lr\": self.lr, \"n\" : self.n, \"n\" : self.threshold}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "        \n",
    "    def sigmoid(self, x, weight):\n",
    "        z = np.dot(x, weight)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.intercept = np.ones((x.shape[0], 1))  \n",
    "        self.x = np.concatenate((self.intercept, x), axis=1)\n",
    "        self.weight = np.zeros(self.x.shape[1])\n",
    "        self.y = y\n",
    "        for i in range(self.n):\n",
    "            sigma = self.sigmoid(self.x, self.weight)\n",
    "            grad = np.dot(self.x.T, (sigma - self.y)) / self.y.shape[0]\n",
    "            self.weight -= self.lr * grad\n",
    "    \n",
    "    def predict(self, x_new):\n",
    "        test_intercept = np.ones((x_new.shape[0], 1))\n",
    "        x_new = np.concatenate((test_intercept, x_new), axis=1)\n",
    "        result = self.sigmoid(x_new, self.weight)\n",
    "        result = result >= self.threshold\n",
    "        y_pred = np.zeros(result.shape[0])\n",
    "        for i in range(len(y_pred)):\n",
    "            if result[i] == True: \n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметры для логистической регрессии через GridSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { \"model__n\": [100, 200], \"model__lr\": np.linspace(0.1, 0.00001, 5)}\n",
    "logreg = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MyLogisticRegression())\n",
    "]) \n",
    "gs = GridSearchCV(estimator=logreg, param_grid=parameters, scoring='accuracy')\n",
    "gs.fit(X_train, y_train)\n",
    "bp = gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу модель и сделаем предсказания, оценим качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8436441982148354\n",
      "Recall: 0.7112068965517241\n",
      "Precision: 0.48162162162162164\n",
      "Roc-auc: 0.7889562406479189\n",
      "Confusion matrix:\n",
      "[[31178  4795]\n",
      " [ 1809  4455]]\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MyLogisticRegression(n=bp[\"model__n\"], lr=bp[\"model__lr\"]))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "preds = logreg.predict(X_test)\n",
    "print_res(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним обученную модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logreg, open('logreg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим и сделаем предсказания с помощью Логистической регрессии в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8456092999029287\n",
      "Recall: 0.7145102971230939\n",
      "Precision: 0.49135135135135133\n",
      "Roc-auc: 0.7916820634907475\n",
      "Confusion matrix:\n",
      "[[31171  4705]\n",
      " [ 1816  4545]]\n"
     ]
    }
   ],
   "source": [
    "logreg_sk = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", LogisticRegression(solver= 'liblinear'))\n",
    "]) \n",
    "logreg_sk.fit(X_train, y_train)\n",
    "preds = logreg_sk.predict(X_test)\n",
    "print_res(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, качество метрик моей логистической регрессии и из sklearn приблизительно одинаковы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k = 5, metric = 'euclidian'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {\"k\": self.k, \"metric\" : self.metric}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        def euclidian(s):\n",
    "            dist = np.sum(((self.x - s) ** 2), axis = 1)\n",
    "            return dist\n",
    "\n",
    "        def manhatten(s):\n",
    "            dist = np.sum(abs(self.x - s), axis = 1)\n",
    "            return dist\n",
    "        \n",
    "        if self.metric == 'euclidean':\n",
    "            dist = np.apply_along_axis(euclidian, 1, X_test)\n",
    "        else:\n",
    "            dist = np.apply_along_axis(manhatten, 1, X_test)\n",
    "\n",
    "        s_dist = np.argsort(dist, axis = 1)\n",
    "        n_dist = s_dist[:, :self.k]\n",
    "        preds = [] \n",
    "        for row in n_dist:\n",
    "            pred = np.argmax(np.bincount(self.y[row]))\n",
    "            preds.append(pred)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как моя реализация KNN работает очень долго на полном датасете, то я беру лишь часть этого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, te = 3000, 1000\n",
    "X_train_small = X_train[:tr]\n",
    "y_train_small = y_train[:tr]\n",
    "X_test_small = X_test[:te]\n",
    "y_test_small = y_test[:te]\n",
    "\n",
    "knn_k = [1, 2, 3, 4]\n",
    "knn_metrics = [\"euclidean\", \"manhatten\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметры для нашей модели KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {\"model__k\": knn_k, \"model__metric\": knn_metrics}\n",
    "knn = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MyKNNClassifier())\n",
    "]) \n",
    "gs_knn = GridSearchCV(knn, parameters_knn, scoring='accuracy')\n",
    "gs_knn.fit(X_train_small, y_train_small)\n",
    "bp = gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также обучим ее и сделаем предсказания, оценим качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806\n",
      "Recall: 0.6190476190476191\n",
      "Precision: 0.18660287081339713\n",
      "Roc-auc: 0.7188087614981958\n",
      "Confusion matrix:\n",
      "[[767 170]\n",
      " [ 24  39]]\n"
     ]
    }
   ],
   "source": [
    "knn = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MyKNNClassifier(k = bp[\"model__k\"], metric = bp[\"model__metric\"]))\n",
    "]) \n",
    "knn.fit(X_train_small, y_train_small)\n",
    "preds = knn.predict(X_test_small)\n",
    "print_res(preds, y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(knn, open('knn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем то же самое для модели из sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794\n",
      "Recall: 0.5283018867924528\n",
      "Precision: 0.1339712918660287\n",
      "Roc-auc: 0.6685860014743679\n",
      "Confusion matrix:\n",
      "[[766 181]\n",
      " [ 25  28]]\n"
     ]
    }
   ],
   "source": [
    "knn_sk = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", KNeighborsClassifier(n_neighbors = 4, metric = \"minkowski\"))\n",
    "])\n",
    "knn_sk.fit(X_train_small, y_train_small)\n",
    "preds = knn_sk.predict(X_test_small)\n",
    "print_res(preds, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n = 100, lr = 0.01, lam = 0.01):\n",
    "        self.n = n\n",
    "        self.lr = lr\n",
    "        self.lam = lam\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {\"n\": self.n, \"lr\": self.lr, \"lam\": self.lam}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n, self.m = X.shape  \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.W = np.zeros(self.m)\n",
    "        self.b = 0\n",
    "        for _ in range(self.n):\n",
    "            for i, x in enumerate(X):\n",
    "                if y[i] * (np.dot(x, self.W) - self.b) >= 1:\n",
    "                    self.W -= self.lr * (2 * self.W * self.lam)\n",
    "                else:\n",
    "                    self.W -= self.lr * (2 * self.W * self.lam - np.dot(x, y[i]))\n",
    "                    self.b -= self.lr * y[i]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.W) - self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моя SVM тоже долго работает на большом датасете, так что я буду использовать маленький:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {\"model__n\": [50, 100], \"model__lr\": [0.01], \"model__lam\": [0.01]}\n",
    "svm = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MySVMClassifier())\n",
    "])\n",
    "gs_svm = GridSearchCV(svm, parameters_svm, scoring='accuracy')\n",
    "gs_svm.fit(X_train_small, np.where(y_train_small > 0, 1, -1))\n",
    "bp = gs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838\n",
      "Recall: 0.6577181208053692\n",
      "Precision: 0.4688995215311005\n",
      "Roc-auc: 0.7636416690983368\n",
      "Confusion matrix:\n",
      "[[740 111]\n",
      " [ 51  98]]\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MySVMClassifier(n = bp[\"model__n\"], lr = bp[\"model__lr\"], lam = bp[\"model__lam\"]))\n",
    "]) \n",
    "svm.fit(X_train_small, np.where(y_train_small > 0, 1, -1))\n",
    "preds = svm.predict(X_test_small)\n",
    "print_res(np.where(preds > 0, 1, 0), y_test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svm, open('svm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n",
      "Recall: 0.7355371900826446\n",
      "Precision: 0.4258373205741627\n",
      "Roc-auc: 0.7995092093757933\n",
      "Confusion matrix:\n",
      "[[759 120]\n",
      " [ 32  89]]\n"
     ]
    }
   ],
   "source": [
    "svm_sk = logreg = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", SVC(gamma='auto'))\n",
    "])\n",
    "svm_sk.fit(X_train_small, np.where(y_train_small > 0, 1, -1))\n",
    "preds = svm_sk.predict(X_test_small)\n",
    "print_res(np.where(preds > 0, 1, 0), y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MyNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = None\n",
    "        self.variance = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = np.zeros((len(self.classes), X.shape[1]), dtype=np.float64)\n",
    "        self.variance = np.zeros((len(self.classes), X.shape[1]), dtype=np.float64)\n",
    "\n",
    "        for j in self.classes:\n",
    "            self.mean[j] = X[j==y].mean(axis=0)\n",
    "            self.variance[j] = X[j==y].var(axis=0)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            probs = [1. for _ in range(len(self.classes))]\n",
    "            for i in range(len(self.classes)):\n",
    "                mean = self.mean[i]\n",
    "                variance = self.variance[i]\n",
    "                e = np.exp(- (x - mean)**2 / (2 * variance))\n",
    "                probs[i] = np.prod((1 / ((2 * math.pi) * variance)**0.5) * e)                       \n",
    "            preds.append(self.classes[np.argmax(probs)])\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7139001349527665\n",
      "Recall: 0.40873373695736187\n",
      "Precision: 0.6860540540540541\n",
      "Roc-auc: 0.6500072413587678\n",
      "Confusion matrix:\n",
      "[[23807  2904]\n",
      " [ 9180  6346]]\n"
     ]
    }
   ],
   "source": [
    "bayes = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", MyNaiveBayes())\n",
    "]) \n",
    "bayes.fit(X_train, y_train)\n",
    "preds = bayes.predict(X_test)\n",
    "print_res(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bayes, open('bayes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7424769751639557\n",
      "Recall: 0.43831981196451586\n",
      "Precision: 0.6249729729729729\n",
      "Roc-auc: 0.6594483940020872\n",
      "Confusion matrix:\n",
      "[[25579  3469]\n",
      " [ 7408  5781]]\n"
     ]
    }
   ],
   "source": [
    "bayes_sk = Pipeline(steps=[\n",
    "    (\"preprocess\", scaler), \n",
    "    (\"model\", GaussianNB())\n",
    "])\n",
    "bayes_sk.fit(X_train, y_train)\n",
    "preds = bayes_sk.predict(X_test)\n",
    "print_res(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "367f2c2972d300ccf432422622a44f7bd9002a905b51a475e9fb8d50e7bb6046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
